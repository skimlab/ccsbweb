---
layout: ccsbtalk
title: "[CCSB Seminar Series] From pathology to MRI and ultrasound, a multimodal information extraction"
speaker: Mirabela Rusu, Ph.D.
speakerurl: https://pimed.stanford.edu/
photo: /images/talks/speakers/mirabela-rusu.jpg
date: 2025-04-16
time: 11:00am
venue: Zoom
venue-inperson: CCSB Conference Room ELEN 231
venue-ece: ECE Conference Room ELEN 315D or Zoom
past-webinar: https://pvpanther.zoom.us/j/98038578074?pwd=ABHJ2XmoJwFCPw2rta24dpVySbmieK.1&from=addon
recording: https://pvpanther.zoom.us/rec/share/dEG4qJWWr-IMEjByl4LWQbQ7ITTrs1kVl8SBkz8h8j3WB08z9ZwtihWsPI25VL4J.uQTlgxNb_BsL_3gP
categories: [blog, talks]
tags: [ccsb-seminar]
event: CCSB-Seminar
---


## Abstract

Clinical care is inherently multimodal, with medical image data collected throughout the patientâ€™s journey.  For example, a patient at risk of cancer will undergo an ultrasound-guided biopsy, and when available with MRI revealing regions to be targeted due to higher risk to harbor aggressive disease. This biopsy procedure seeks to collect tissue samples for pathology and will inform treatment strategies for best outcomes. This common scenario provides unique opportunities for Artificial Intelligence (AI) methods to effectively integrate multimodal data, and learn imaging signatures in patients with known outcomes, to enable early cancer detection for patients at risk. My research focuses on developing AI methods that bridge the gap between highly informative modalities, e.g., pathology or MRI, and lower resolution modalities, e.g., ultrasound. These methods rely on multimodal image registration, image feature fusion, or integration of patient-specific data and population-specific information and rely on AI approaches for effective integration. While the learning is done with multiple imaging modalities, the inference requires only the low-resolution modality, e.g., ubiquitous conventional ultrasound, with applications in low-resource settings. These methods are applied to detect cancer and its aggressive extent in various cancers, e.g. prostate, kidney, or breast.


## Speaker Bio

[Dr. Rusu](https://med.stanford.edu/profiles/mirabela-rusu) is an Assistant Professor, in the [Department of Radiology](https://med.stanford.edu/radiology.html), and, by courtesy, [Department of Urology and Biomedical Data Science](https://dbds.stanford.edu/), at [Stanford University](https://www.stanford.edu), where she leads the [Personalized Integrative Medicine Laboratory (PIMed)](https://pimed.stanford.edu). The PIMed Laboratory has a multi-disciplinary direction and focuses on developing analytic methods for biomedical data integration, with a particular interest in multimodal fusion, e.g., radiology-pathology fusion to facilitate radiology image labeling, or MRI-ultrasound for guiding procedure. These fusion approaches allow the downstream training of advanced multimodal machine learning for cancer detection and subtype identification at pixel-level. Our approaches have been applied in oncologic (prostate, breast, kidney) and non-oncologic applications.

Dr. Rusu received a Master of Engineering in Bioinformatics from the National Institute of Applied Sciences in Lyon, France. She continued her training at the University of Texas Health Science Center in Houston, where she received a Master of Science and PhD degree in Health Informatics for her work in biomolecular structural data integration of cryo-electron micrographs and X-ray crystallography models.

During her postdoctoral training at Rutgers and Case Western Reserve University, Dr. Rusu has developed computational tools for the integration and interpretation of multi-modal medical imaging data and focused on studying prostate and lung cancers. Prior to joining Stanford, Dr. Rusu was a Lead Engineer and Medical Image Analysis Scientist at GE Global Research Niskayuna NY where she was involved in the development of analytic methods to characterize biological samples in microscopy images and pathologic conditions in MRI or CT. 
 

